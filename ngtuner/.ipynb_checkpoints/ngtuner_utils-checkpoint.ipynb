{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting helper_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile helper_functions.py\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import string\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "from functools import wraps\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, roc_auc_score,log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.image import MIMEImage\n",
    "\n",
    "from os.path import basename\n",
    "\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "import marshal\n",
    "import tempfile\n",
    "import pprint\n",
    "import psutil\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import objgraph\n",
    "\n",
    "import pickle\n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "# bit-serialize any object.Creates a new file if none, else appends.\n",
    "# returns pickled object if only path is supplied\n",
    "# stores the object in a dictionary with obj_key as key\n",
    "def pickler(path, obj_to_pickle = None, obj_key = None):\n",
    "\n",
    "\n",
    "    save ={}\n",
    "    \n",
    "    if exists(path):\n",
    "        try:\n",
    "          f = open(path, 'rb')\n",
    "          save = pickle.load(f)\n",
    "          f.close()\n",
    "        except Exception as e:\n",
    "          print('Unable to read data from', context['pickle'], ':', e)\n",
    "          raise\n",
    "\n",
    "    if(obj_to_pickle):\n",
    "        save.update({obj_key: obj_to_pickle})\n",
    "\n",
    "        try:\n",
    "          f = open(path, 'wb')\n",
    "          pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "          f.close()\n",
    "        except Exception as e:\n",
    "          print('Unable to save data to', context['pickle'], ':', e)\n",
    "          raise\n",
    "    \n",
    "    return save\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Writes a dictionary to the file at supplied path.\n",
    "# Optional description text describing the dictionary\n",
    "\n",
    "def write_dict(d, path, description =''):\n",
    "\n",
    "    \n",
    "    with open(path, \"a\") as f:\n",
    "      h_line = '-------------------------------\\n'\n",
    "      f.write(h_line)\n",
    "      f.write(description +'\\n')\n",
    "      for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "          write_dict(v, path)\n",
    "        else:\n",
    "            tmp_str = str(k) + ' : ' + str(v) +'\\n'\n",
    "            f.write(tmp_str)\n",
    "      f.write(h_line)\n",
    "    \n",
    "    return(d)\n",
    "\n",
    "\n",
    "def load_dataset(name, context):\n",
    "    load_stats ={}\n",
    "    size = 50\n",
    "    image_size = 28\n",
    "    num_labels =  10\n",
    "    data = name\n",
    "\n",
    "    data_pickle_path = '../../../../tensorflow/tensorflow/examples/udacity/' + data\n",
    "\n",
    "    with open(data_pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    train_dataset = data['train_dataset']\n",
    "    length = train_dataset.shape[0]\n",
    "\n",
    "    train_dataset = train_dataset.reshape(length, image_size*image_size)\n",
    "\n",
    "    valid_dataset = data['valid_dataset']\n",
    "    length = valid_dataset.shape[0]\n",
    "    valid_dataset = valid_dataset.reshape(length, image_size*image_size)\n",
    "\n",
    "    test_dataset = data['test_dataset']\n",
    "    length = valid_dataset.shape[0]\n",
    "    test_dataset = test_dataset.reshape(length, image_size*image_size)\n",
    "\n",
    "    valid_labels = data['valid_labels']\n",
    "    train_labels = data['train_labels']\n",
    "    test_labels = data['test_labels']\n",
    "\n",
    "    #be nice to your RAM\n",
    "    del data\n",
    "\n",
    "    load_stats.update({'training dataset': train_dataset.shape})\n",
    "    load_stats.update({'training labels': train_labels.shape})\n",
    "    load_stats.update({'validations dataset': valid_dataset.shape})\n",
    "    load_stats.update({'validation labels': valid_labels.shape})\n",
    "    load_stats.update({'test dataset': test_dataset.shape})\n",
    "    load_stats.update({'test labels': test_labels.shape})\n",
    "\n",
    "    ############## WRITE TO SUMMARY FILE\n",
    "    write_dict(load_stats, context['summary'],'Dataset Details')\n",
    "\n",
    "    datasets = [train_dataset, valid_dataset, test_dataset]\n",
    "    labels = [train_labels, valid_labels, test_labels]\n",
    "    return datasets, labels\n",
    "\n",
    "\n",
    "\n",
    "#computes max_memory and cpu usage from dictionary of measured results \n",
    "def max_stats(profile_results, context):\n",
    "    cpu_list= []\n",
    "    used_memory_list =[]\n",
    "    active_memory_list =[]\n",
    "    total_memory_list = []\n",
    "    buffered_memory_list =[]\n",
    "    cached_memory_list =[]\n",
    "    shared_memory_list = []\n",
    "    swap_memory_list = []\n",
    "    return_dict= {}\n",
    "\n",
    "\n",
    "    for i, (key,value) in enumerate(profile_results.items()):\n",
    "\n",
    "        if not key == 'max_memory':\n",
    "            cpu_list.append(value['all_cpu'])             \n",
    "            total_memory_list.append(value['memory'][0])\n",
    "            used_memory_list.append(value['memory'][3])\n",
    "            active_memory_list.append(value['memory'][5])\n",
    "            buffered_memory_list.append(value['memory'][7])\n",
    "            cached_memory_list.append(value['memory'][8])\n",
    "            shared_memory_list.append(value['memory'][9])\n",
    "            swap_memory_list.append(value['swap'][0])\n",
    "            \n",
    "            \n",
    "    max_memory = profile_results['max_memory']  \n",
    "    \n",
    "    return_dict.update({'max_cpu': np.max(cpu_list)})\n",
    "    return_dict.update({'total_memory': convert_size(np.max(total_memory_list))})\n",
    "    return_dict.update({'max_used_memory': convert_size(np.max(used_memory_list))})\n",
    "    return_dict.update({'max_active_memory': convert_size(np.max(active_memory_list))})\n",
    "    return_dict.update({'max_buffered_memory': convert_size(np.max(buffered_memory_list))})\n",
    "    return_dict.update({'max_cached_memory': convert_size(np.max(cached_memory_list))})\n",
    "    return_dict.update({'max_shared_memory': convert_size(np.max(shared_memory_list))})\n",
    "    return_dict.update({'max_swapped_memory': convert_size(np.max(swap_memory_list))})\n",
    "    return_dict.update({'max_thread_memory': max_memory})\n",
    "\n",
    "    \n",
    "    write_dict(return_dict, context['summary'], 'Maximum Usage Stats')\n",
    "    pickled = pickler(context['pickle'], return_dict, 'max stats')\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "\n",
    "\n",
    "#sends email to self from self, with passed subject and body\n",
    "#Files to attach can be passed as list to the 'files' argument\n",
    "\n",
    "def send_email(subject, body, version_list_html='', files=None, context = None):\n",
    "    \n",
    "    def prompt(prompt):\n",
    "        return raw_input(prompt).strip()\n",
    "\n",
    "    fromaddr = 'abhijeet.jha@gmail.com'\n",
    "    toaddr  = 'abhijeet.jha@gmail.com'\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = fromaddr\n",
    "    msg['To'] = toaddr\n",
    "    msg['Subject'] = subject\n",
    "    \n",
    "    body = body\n",
    "    \n",
    "    msg.attach(MIMEText(body, 'html'))\n",
    "    \n",
    "    \n",
    "    footer =\"<br>><hr>\" + version_list_html\n",
    "    msg.attach(MIMEText(footer, 'html'))\n",
    "\n",
    "    \n",
    "    #######################################\n",
    "#     To embed accuracy image\n",
    "#     pickled = pickler(context['pickle'])\n",
    "#     img = pickled['accuracy plot']\n",
    "\n",
    "\n",
    "\n",
    "#     # This example assumes the image is in the current directory\n",
    "#     fp = open(img, 'rb')\n",
    "#     msgImage = MIMEImage(fp.read())\n",
    "#     fp.close()\n",
    "\n",
    "#     # Define the image's ID as referenced above\n",
    "#     msgImage.add_header('Content-ID', '<image1>')\n",
    "#     msg.attach(msgImage)\n",
    "\n",
    "\n",
    "####################################\n",
    "    for f in files or []:\n",
    "        with open(f, \"rb\") as fil:\n",
    "            part = MIMEApplication(\n",
    "                fil.read(),\n",
    "                Name=basename(f)\n",
    "            )\n",
    "            part['Content-Disposition'] = 'attachment; filename=\"%s\"' % basename(f)\n",
    "            msg.attach(part)\n",
    "\n",
    "    \n",
    " \n",
    "    smtp_server = 'email-smtp.us-east-1.amazonaws.com'\n",
    "    smtp_username = 'AKIAJFYKGSZH6TNFD2WQ'\n",
    "    smtp_password = 'AoSGycN2iVoV9b/eDhm6ht2ZK7OaRa58InGKywLQ/nfF'\n",
    "    smtp_port = '587'\n",
    "    smtp_do_tls = True\n",
    "\n",
    "    server = smtplib.SMTP(\n",
    "        host = smtp_server,\n",
    "        port = smtp_port,\n",
    "        timeout = 10\n",
    "        )\n",
    "    server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login(smtp_username, smtp_password)\n",
    "    \n",
    "    text = msg.as_string()\n",
    "    server.sendmail(fromaddr, toaddr, text)\n",
    "\n",
    "    \n",
    "# create html markup for a dictionay. \n",
    "# Note - doesnt work with nested dictionaries\n",
    "#TO DO - write an iterator \n",
    "def dict_to_html(dict):\n",
    "    df=pd.DataFrame(dict)\n",
    "    outhtml= df.to_html(na_rep = \"\", index = True).replace('border=\"1\"','border=\"0\"')\n",
    "    outhtml=outhtml.replace('<th>','<th style = \"display: none\">')\n",
    "    outhtml=outhtml.replace('<td>','<td style= \"padding: 8px;text-align: left;border-bottom: 1px solid #ddd;;\">')\n",
    "    outhtml=outhtml.replace('table','table width = \"100%\"')\n",
    "    return outhtml\n",
    "\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "# dataset and labels are of type np.ndarray, returned by merge_dataset()\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "\n",
    "\n",
    "def fetch_paths():\n",
    "    today = datetime.date.today().strftime(\"%Y%m%d\")\n",
    "    now = time.strftime(\"%H%M%S\",time.gmtime())\n",
    "\n",
    "    \n",
    "    model_path = 'savedmodels/' + today +'/'\n",
    "    log_path = 'logs/' + today +'/'\n",
    "    stats_path = 'stats/' + today +'/'\n",
    "    runprofiles_path = 'runprofiles/' + today +'/'\n",
    "    pickle_path = 'runpickles/' + today + '/'\n",
    "    plot_path = 'plots/' + today + '/' + 'run_' + now +'/'\n",
    "    \n",
    "    current = str(os.getcwd())\n",
    "    log_root = os.path.join(log_path)\n",
    "    model_root = os.path.join(model_path)\n",
    "    stats_root = os.path.join(stats_path)\n",
    "    runprofiles_root = os.path.join(runprofiles_path)\n",
    "    pickled_root = os.path.join(pickle_path)\n",
    "    plot_root = os.path.join(plot_path)\n",
    "\n",
    "    if not os.path.exists(model_root):\n",
    "        os.makedirs(model_root)\n",
    "\n",
    "    if not os.path.exists(log_root):\n",
    "        os.makedirs(log_root)\n",
    "        \n",
    "    if not os.path.exists(stats_root):\n",
    "        os.makedirs(stats_root)\n",
    "        \n",
    "    if not os.path.exists(runprofiles_root):\n",
    "        os.makedirs(runprofiles_root)\n",
    "    \n",
    "    if not os.path.exists(pickled_root):\n",
    "        os.makedirs(pickled_root)\n",
    "    \n",
    "    if not os.path.exists(plot_root):\n",
    "        os.makedirs(plot_root)\n",
    "        \n",
    "    summary = runprofiles_root + 'summary_' + today + now + '.txt'\n",
    "    pickle = pickled_root + 'run_' + today + now \n",
    "    modelpickles = model_root + 'pickled_' + today + now\n",
    "    statsfile = stats_root + 'stats_' + today + now\n",
    "    \n",
    "    context ={}\n",
    "    context.update({'log path': log_root})\n",
    "    context.update({'plot path': plot_root})\n",
    "    context.update({'model path': model_root})\n",
    "    context.update({'stats path': stats_root})\n",
    "    context.update({'runprofiles path': runprofiles_root})\n",
    "    context.update({'run date': today})\n",
    "    context.update({'run time': now})\n",
    "    context.update({'summary': summary})\n",
    "    context.update({'pickle': pickle})\n",
    "    context.update({'modelpickles': modelpickles})\n",
    "    context.update({'statsfile': statsfile})\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def html_class_name(class_name):\n",
    "    #class_name = class_name.replace(\"<class '\", \"\")\n",
    "    class_name = class_name.replace(\">\", \"\")\n",
    "    class_name = class_name.replace(\"<\", \"\")\n",
    "    class_name = class_name.replace(\"'\", \"\")\n",
    "    class_name = class_name.replace(\" \", \"\")\n",
    "    class_name = class_name.replace(\".\", \"\")\n",
    "    class_name = class_name.replace(\":\", \"\")\n",
    "    return class_name\n",
    "\n",
    "\n",
    "\n",
    "# Routine to add commas to a float string\n",
    "def commify3(amount):\n",
    "    amount = str(amount)\n",
    "    amount = amount[::-1]\n",
    "    amount = re.sub(r\"(\\d\\d\\d)(?=\\d)(?!\\d*\\.)\", r\"\\1,\", amount)\n",
    "    return amount[::-1]\n",
    "\n",
    "\n",
    "\n",
    "def save_summary(context, stats_file_path):\n",
    "    #print (\" --------------------------------------------------------------------\")\n",
    "    #summary = context['runprofiles path'] + 'summary_'+ context['run time'] +'.txt'\n",
    "    stream = open(os.path.join(context['summary']), 'a');\n",
    "    stats = pstats.Stats(stats_file_path, stream=stream)\n",
    "    pprint.pformat(stats.strip_dirs().sort_stats('cumtime').print_stats(15))\n",
    "    stream.flush()\n",
    "    stream.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def poll_system_profile(context, interval=0.0):\n",
    "    #log_root, model_root, stats_root, today, now = fetch_paths()    \n",
    "    num_cpu =psutil.cpu_count()\n",
    "    percpu_list =[]\n",
    "    \n",
    "    # Current system-wide CPU utilization as a percentage\n",
    "    # ---------------------------------------------------\n",
    " \n",
    "    # Individual CPUs\n",
    "    sys_percs_percpu = psutil.cpu_percent(interval, percpu=True)\n",
    "    \n",
    "    \n",
    "    for cpu_num, perc in enumerate(sys_percs_percpu):\n",
    "        percpu_list.append(perc)\n",
    "    # end for\n",
    " \n",
    " \n",
    "    # Details on Current system-wide CPU utilziation as a percentage\n",
    " \n",
    "    # --------------------------------------------------------------\n",
    "    # Server as a whole\n",
    "    overall_cpu = np.mean(percpu_list)\n",
    "    sys_percs_total_details = psutil.cpu_times_percent(interval, percpu=False)\n",
    "    mem = psutil.virtual_memory()\n",
    "    swap = psutil.swap_memory()\n",
    "    used = mem.total - mem.available\n",
    "    sys_cpu_times = {}\n",
    "    \n",
    "    sys_cpu_times.update({'profile_time': datetime.date.today().strftime(\"%Y%m%d\") + time.strftime(\"%H%M%S\",time.gmtime()) })\n",
    "    sys_cpu_times.update({'all_cpu': overall_cpu})\n",
    "    sys_cpu_times.update({'per_cpu': sys_percs_percpu})\n",
    "    sys_cpu_times.update({'memory': mem})\n",
    "    sys_cpu_times.update({'swap':swap})\n",
    "    \n",
    "    write_dict(sys_cpu_times, context['summary'], 'Usage Logging')\n",
    "    \n",
    "\n",
    "    \n",
    "    return sys_cpu_times\n",
    "\n",
    "   \n",
    "\n",
    "def measure_memory_usage(context, target_call, target_args, log_interval=30, log_filename=None, memory_usage_refresh=0.01):\n",
    "    \"\"\"\n",
    "    measure the memory usage of a function call in python.\\n\n",
    "    Note: one may have to restart python to get accurate results.\\n\n",
    "    :param target_call: function to be tested\\n\n",
    "    :param target_args: arguments of the function in a tuple\\n\n",
    "    :param memory_usage_refresh: how frequent the memory is measured, default to 0.005 seconds\\n\n",
    "    :return: max memory usage in kB (on Linux/Ubuntu 14.04), may depend on OS\n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    class StoppableThread(threading.Thread):\n",
    "        def __init__(self, target, args):\n",
    "            super(StoppableThread, self).__init__(target=target, args=args)\n",
    "            self.daemon = True\n",
    "            self.__monitor = threading.Event()\n",
    "            self.__monitor.set()\n",
    "            self.__has_shutdown = False\n",
    "\n",
    "        def run(self):\n",
    "            '''Overloads the threading.Thread.run'''\n",
    "            # Call the User's Startup functions\n",
    "            self.startup()\n",
    "\n",
    "            # use the run method from Superclass threading.Thread\n",
    "            super(StoppableThread, self).run()\n",
    "\n",
    "            # Clean up\n",
    "            self.cleanup()\n",
    "\n",
    "            # Flag to the outside world that the thread has exited\n",
    "            # AND that the cleanup is complete\n",
    "            self.__has_shutdown = True\n",
    "\n",
    "        def stop(self):\n",
    "            self.__monitor.clear()\n",
    "\n",
    "        def isRunning(self):\n",
    "            return self.__monitor.isSet()\n",
    "\n",
    "        def isShutdown(self):\n",
    "            return self.__has_shutdown\n",
    "\n",
    "        def mainloop(self):\n",
    "            '''\n",
    "            Expected to be overwritten in a subclass!!\n",
    "            Note that Stoppable while(1) is handled in the built in \"run\".\n",
    "            '''\n",
    "            pass\n",
    "\n",
    "        def startup(self):\n",
    "            '''Expected to be overwritten in a subclass!!'''\n",
    "            pass\n",
    "\n",
    "        def cleanup(self):\n",
    "            '''Expected to be overwritten in a subclass!!'''\n",
    "            pass\n",
    "\n",
    "    class MyLibrarySniffingClass(StoppableThread):\n",
    "        def __init__(self, target, args):\n",
    "            super(MyLibrarySniffingClass, self).__init__(target=target, args=args)\n",
    "            self.target_function = target\n",
    "            self.results = None\n",
    "\n",
    "        def startup(self):\n",
    "            # Overload the startup function\n",
    "            print (\"Calling the Target Library Function...\")\n",
    "\n",
    "        def cleanup(self):\n",
    "            # Overload the cleanup function\n",
    "            print (\"Library Call Complete\")\n",
    "\n",
    "        #process = psutil.Process(os.getpid())\n",
    "\n",
    "   \n",
    "    process = psutil.Process(os.getpid())\n",
    "    my_thread = MyLibrarySniffingClass(target_call, target_args)\n",
    "    \n",
    "    run_profile ={}\n",
    "    start_mem = process.memory_full_info().uss  #uss\n",
    "    \n",
    "    sys_profile = poll_system_profile(context, interval=0.1)\n",
    "    print (\"Written to summary File\")\n",
    "    \n",
    "    run_profile.update({time.strftime(\"%H:%M:%S\",time.gmtime()): sys_profile})\n",
    "    \n",
    "    my_thread.start()\n",
    "    delta_mem = 0\n",
    "    max_memory = 0\n",
    "    last_run=time.time()\n",
    "\n",
    "    while(True):\n",
    "        time.sleep(memory_usage_refresh)\n",
    "        cur_time = time.time()\n",
    "        del_time = cur_time - last_run\n",
    "        \n",
    "        \n",
    "        \n",
    "        if round(del_time) > log_interval:\n",
    "            sys_profile = poll_system_profile(context)\n",
    "            print (\"Written to summary File\")\n",
    "            last_run = cur_time\n",
    "            run_profile.update({time.strftime(\"%H:%M:%S\",time.gmtime()): sys_profile})\n",
    "            #print(run_profile)\n",
    "        \n",
    "        current_mem = process.memory_info().rss \n",
    "        delta_mem = current_mem - start_mem\n",
    "        if delta_mem > max_memory:\n",
    "            max_memory = delta_mem\n",
    "\n",
    "            \n",
    "        if my_thread.isShutdown():\n",
    "            print (\"Memory measurement complete!\")\n",
    "            break\n",
    "\n",
    "    current_mem = process.memory_full_info().uss  #uss\n",
    "    delta_mem = current_mem - start_mem\n",
    "    if delta_mem > max_memory:\n",
    "        max_memory = delta_mem\n",
    "\n",
    "\n",
    "\n",
    "    print (\"MAX Memory Usage in MB: {}\".format( convert_size(max_memory)))\n",
    "\n",
    "    \n",
    "    run_profile.update({time.strftime(\"%H:%M:%S\",time.gmtime()): sys_profile})\n",
    "    run_profile.update({'max_memory': convert_size(max_memory)})\n",
    "   \n",
    "    \n",
    "    written = max_stats(run_profile, context)\n",
    "    \n",
    "    return written\n",
    "\n",
    "\n",
    "\n",
    "def objects_growth(path, description = ''):\n",
    "    \n",
    "    \n",
    "    orig_stdout = sys.stdout\n",
    "    \n",
    "    f = open(path, 'a')\n",
    "    sys.stdout = f\n",
    "    \n",
    "    print(description)\n",
    "    f.flush()\n",
    "    \n",
    "    print(sys.version)\n",
    "    print(\"---------------\")\n",
    "    print(\"Object Growth\")\n",
    "    print(objgraph.show_growth()) \n",
    "    f.flush()\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    sys.stdout = orig_stdout\n",
    "    #return''\n",
    "\n",
    "\n",
    "    \n",
    "parameter_ranges = {\n",
    "    'colsample_bylevel': [0.4, 1.0],\n",
    "    'colsample_bytree': [0.4, 1.0],\n",
    "    'subsample': [0.4, 1.0],\n",
    "\n",
    "    'learning_rate': [0, 1],\n",
    "    'n_estimators': [15, 1000],\n",
    "    \n",
    "    'max_depth': [1,15],\n",
    "    'min_child_weight': [1,15],\n",
    "    'gamma': [0, 1],\n",
    "\n",
    "    'reg_alpha': [-3,2],   #powers of 10\n",
    "    'reg_lambda': [-3,2]}  #powers of 10\n",
    "\n",
    "\n",
    "\n",
    "def tuner(diagnosis, in_parameters, context):\n",
    "    out_parameters = in_parameters.copy()\n",
    "    \n",
    "    if diagnosis == 'High Variance':\n",
    "    \n",
    "        #'colsample_bylevel' - reduce value to increase regularization\n",
    "        left = min(parameter_ranges['colsample_bylevel']) *100 \n",
    "        right = in_parameters['colsample_bylevel'] *100 \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "        out_parameters.update({'colsample_bylevel': new_value/100})\n",
    "    \n",
    "        #'colsample_bytree' - reduce value to increase regularization\n",
    "        left = min(parameter_ranges['colsample_bytree']) *100 \n",
    "        right = in_parameters['colsample_bytree'] *100 \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "        out_parameters.update({'colsample_bytree': new_value/100})\n",
    "    \n",
    "        #'subsample' - reduce value to increase regularization\n",
    "        left = min(parameter_ranges['subsample']) *100 \n",
    "        right = in_parameters['subsample'] *100 \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "        out_parameters.update({'subsample': new_value/100})\n",
    "        \n",
    "        #'max_depth' - reduce value to decrease model complexity\n",
    "        left = min(parameter_ranges['max_depth']) \n",
    "        right = in_parameters['max_depth'] \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "\n",
    "        out_parameters.update({'max_depth': new_value})\n",
    "        \n",
    "        #'min_child_weight' - increase to reduce model complexity\n",
    "        left = in_parameters['min_child_weight'] \n",
    "        right = max(parameter_ranges['min_child_weight']) \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "            \n",
    "        out_parameters.update({'min_child_weight': new_value})\n",
    "        \n",
    "        #'gamma' - increase to reduce model complexity\n",
    "        left = in_parameters['gamma']  * 100 \n",
    "        right = max(parameter_ranges['gamma']) *100 \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right)  \n",
    "        \n",
    "        out_parameters.update({'gamma': new_value/100})\n",
    "        \n",
    "        #'alpha' - increase to reduce model complexity\n",
    "        left =  (np.log10(1.0 / in_parameters['reg_alpha']) * -1) \n",
    "        right = max(parameter_ranges['reg_alpha']) \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = np.power(10, float(left))\n",
    "        else:\n",
    "            new_value = np.power(10, float(np.random.randint(left,right)))\n",
    "        \n",
    "        \n",
    "        new_value = round(new_value, 4)\n",
    "        out_parameters.update({'reg_alpha':new_value})\n",
    "        \n",
    "        #'lambda' - increase to reduce model complexity\n",
    "        left =  (np.log10(1.0 / in_parameters['reg_lambda']) * -1) \n",
    "        right = max(parameter_ranges['reg_lambda']) \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = np.power(10, float(left))\n",
    "        else:\n",
    "            new_value = np.power(10, float(np.random.randint(left,right)))\n",
    "        \n",
    "\n",
    "        out_parameters.update({'reg_lambda': round(new_value,4)})\n",
    "    \n",
    "    \n",
    "    if diagnosis == 'High Bias':\n",
    "    \n",
    "        #'colsample_bylevel' - increase value to reduce regularization\n",
    "        left = in_parameters['colsample_bylevel'] *100 \n",
    "        right = max(parameter_ranges['colsample_bylevel']) *100 +1\n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "\n",
    "        out_parameters.update({'colsample_bylevel': new_value/100})\n",
    "    \n",
    "        #'colsample_bytree' - increase value to reduce regularization\n",
    "        left = in_parameters['colsample_bytree'] *100 \n",
    "        right = max(parameter_ranges['colsample_bytree']) *100 +1\n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "\n",
    "        out_parameters.update({'colsample_bytree': new_value/100})\n",
    "    \n",
    "        #'subsample' - increase value to reduce regularization\n",
    "        left = in_parameters['subsample'] *100 \n",
    "        right = max(parameter_ranges['subsample']) *100 +1\n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "        out_parameters.update({'subsample': new_value/100})\n",
    "        \n",
    "        #'max_depth' - increase value to increase model complexity\n",
    "        left = in_parameters['max_depth'] \n",
    "        right = max(parameter_ranges['max_depth']) +1\n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "        out_parameters.update({'max_depth': new_value})\n",
    "        \n",
    "        #'min_child_weight' - decrease to increase model complexity\n",
    "        right = in_parameters['min_child_weight'] \n",
    "        left = min(parameter_ranges['min_child_weight'])\n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "\n",
    "        out_parameters.update({'min_child_weight': new_value})\n",
    "        \n",
    "        #'gamma' - reduce to increase model complexity\n",
    "        right = in_parameters['gamma']  * 100 \n",
    "        left = min(parameter_ranges['gamma']) *100 \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = left\n",
    "        else:\n",
    "            new_value = np.random.randint(left,right) \n",
    "        \n",
    "        out_parameters.update({'gamma': new_value/100 })\n",
    "        \n",
    "        #'alpha' - decrease to increase model complexity\n",
    "        right =  (np.log10(1.0 / in_parameters['reg_alpha']) * -1) + 1 \n",
    "        left = min(parameter_ranges['reg_alpha']) \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = np.power(10, left)\n",
    "        else:\n",
    "            new_value = np.power(10, float(np.random.randint(left,right)))\n",
    "        \n",
    "        new_value = round(new_value, 4)\n",
    "        out_parameters.update({'reg_alpha':new_value})\n",
    "        \n",
    "        #'lambda' - decrease to reduce model complexity\n",
    "        right =  (np.log10(1.0 / in_parameters['reg_lambda']) * -1) + 1 \n",
    "        left = min(parameter_ranges['reg_lambda']) \n",
    "        \n",
    "        if left == right:\n",
    "            new_value = np.power(10, left)\n",
    "        else:\n",
    "            new_value = np.power(10, float(np.random.randint(left,right)))\n",
    "        \n",
    "        out_parameters.update({'reg_lambda': round(new_value,4)})\n",
    "        \n",
    "\n",
    "    #pprint.pprint(in_parameters)\n",
    "    #pprint.pprint(out_parameters)\n",
    "    \n",
    "    return out_parameters\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def meter(result, context, threshold = 0.05, human_accuracy = 1.0):\n",
    "    train_accuracy = 1.0 - result[0,0]\n",
    "    valid_accuracy = 1.0 - result[0,1]\n",
    "    test_accuracy = 1.0 - result[0,2]\n",
    "    \n",
    "    \n",
    "\n",
    "    bias = abs(human_accuracy - train_accuracy)\n",
    "    variance = abs(valid_accuracy - train_accuracy)\n",
    "    \n",
    "#     print(train_accuracy,valid_accuracy,test_accuracy)\n",
    "#     print(bias,variance, threshold)\n",
    "    \n",
    "    if bias < threshold:\n",
    "        if variance < threshold:\n",
    "            return('tuned') \n",
    "        else:\n",
    "            return('High Variance')\n",
    "    else:\n",
    "        return('High Bias')    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def ngtuner( datasets, context, interval=0):\n",
    "    \"\"\"Andrew Ng's recipe\n",
    "    \"\"\"\n",
    "    def callback(env):\n",
    "\n",
    "        if interval > 0 and env.iteration % interval == 0:\n",
    "\n",
    "            cv = len(env.cvfolds)\n",
    "            res = np.zeros((cv,3))\n",
    "            for i, cvpack in enumerate(env.cvfolds):\n",
    "                eval_result = cvpack.bst.eval_set(datasets)\n",
    "                \n",
    "                lis = re.split(r'\\\\t+', str(eval_result))\n",
    "                train_s = re.split(r':+', lis[1])   \n",
    "                valid_s = re.split(r':+', lis[2]) \n",
    "                test_s =  re.split(r':+', lis[3]) \n",
    "\n",
    "                #print(train_s[1],valid_s[1],test_s[1])\n",
    "                res[i,0] = float(train_s[1])\n",
    "                res[i,1] = float(valid_s[1])\n",
    "                res[i,2] = float(test_s[1].rstrip(\"'\"))\n",
    "    \n",
    "            avg = np.mean(res, axis=0)\n",
    "            avg= avg.reshape(1,3)\n",
    "            print('Average= ', avg)\n",
    "\n",
    "        \n",
    "            diag = meter(avg, context,threshold = 0.05, human_accuracy = 1.0)\n",
    "            print(diag)\n",
    "        \n",
    "            pickled = pickler(context['pickle'])\n",
    "            parameters = pickled['optimal parameters']\n",
    "            new_params = tuner(diag, parameters, context)\n",
    "            pickled = pickler(context['pickle'], new_params, 'optimal parameters')\n",
    "        \n",
    "            pprint.pprint(new_params)\n",
    "        \n",
    "            for cvpack in env.cvfolds:\n",
    "                bst = cvpack.bst\n",
    "                bst.set_param(new_params)\n",
    "            \n",
    "\n",
    "    \n",
    "    callback.before_iteration = True\n",
    "    \n",
    "    return callback\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def modelfit(alg, datasets, labels, context, metrics, interval = 0, useTrainCV=True, cv_folds=3, early_stopping_rounds=20, num_labels = None):\n",
    "      \n",
    "    try:\n",
    "          train_dataset= datasets[0]\n",
    "          train_labels = labels[0]\n",
    "    except Exception as e:\n",
    "          print('Unable to save data to load training samples', e)\n",
    "          raise\n",
    "    \n",
    "    valid_dataset = datasets[1]\n",
    "    test_dataset = datasets[2]\n",
    "    \n",
    "   \n",
    "    valid_labels = labels[1]\n",
    "    test_labels = labels[2]\n",
    "\n",
    "    \n",
    "    run_stats={}\n",
    "    optimal_boosters = 0\n",
    "    num_class = num_labels\n",
    "    \n",
    "    \n",
    "    if useTrainCV:\n",
    "\n",
    "        \n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        \n",
    "        write_dict(xgb_param, context['summary'],' Initial Parameters')\n",
    "        xgb_param.update({'num_class': num_class})\n",
    "        updated_pickle = pickler(context['pickle'], xgb_param, 'optimal parameters')\n",
    "\n",
    "\n",
    "        xgtrain = xgb.DMatrix(train_dataset,label=train_labels)\n",
    "        xgvalid = xgb.DMatrix(valid_dataset,label=valid_labels)\n",
    "        xgtest = xgb.DMatrix(test_dataset,label=test_labels)\n",
    "        \n",
    "        xgdataset = [(xgtrain, 'Train'),(xgvalid, 'Valid'), (xgtest, 'Test')]\n",
    "        \n",
    "\n",
    "        \n",
    "        cv_start_time = time.time()\n",
    "        \n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds,metrics=metrics, \n",
    "                          early_stopping_rounds=early_stopping_rounds,callbacks=[ngtuner( xgdataset, context, interval)])\n",
    "        cv_end_time = time.time()\n",
    "        \n",
    "\n",
    "        \n",
    "        cv_time_raw = cv_end_time - cv_start_time\n",
    "        cv_time = time.strftime(\"%H:%M:%S s\",time.gmtime(cv_time_raw))\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    " \n",
    "        alg.set_params(n_estimators = cvresult.shape[0])\n",
    "        optimal_boosters = cvresult.shape[0]\n",
    "\n",
    "        \n",
    "    #Fit the algorithm on the data\n",
    "    fit_start_time =time.time()\n",
    "    alg.fit(train_dataset, train_labels,eval_metric=metrics)\n",
    "    fit_end_time =time.time()\n",
    "    \n",
    "    fit_time_raw = fit_end_time - fit_start_time\n",
    "    fit_time = time.strftime(\"%H:%M:%S s\",time.gmtime(fit_time_raw))\n",
    "\n",
    "   \n",
    "    #Predict training and validation set:\n",
    "    predict_start_time = time.time()\n",
    "    dtrain_predictions = alg.predict(train_dataset)\n",
    "    dvalid_predictions = alg.predict(valid_dataset)\n",
    "    dtest_predictions = alg.predict(test_dataset)\n",
    "    predict_end_time = time.time()\n",
    "    \n",
    "    predict_time_raw = predict_end_time - predict_start_time\n",
    "    predict_time = time.strftime(\"%H:%M:%S s\",time.gmtime(predict_time_raw))\n",
    "\n",
    "    \n",
    "    write_dict({'train time': cv_time, 'fit time': fit_time, 'predict time': predict_time}, context['summary'],'Run Times')\n",
    "\n",
    "        \n",
    "     #Print model report:\n",
    "    acc_score_train = accuracy_score(train_labels, dtrain_predictions)\n",
    "    acc_score_valid = accuracy_score(valid_labels, dvalid_predictions)\n",
    "    acc_score_test = accuracy_score(test_labels, dtest_predictions)\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : {0:.5f}\".format(acc_score_test)) \n",
    "    print (\"Optimal Boosters : {}\".format(optimal_boosters)) \n",
    "    \n",
    "    run_stats.update({'Train Accuracy': acc_score_train})\n",
    "    if acc_score_valid: run_stats.update({'Validation Accuracy': acc_score_valid})\n",
    "    if acc_score_test: run_stats.update({'Test Accuracy': acc_score_test})\n",
    "\n",
    "    pickled = pickler(context['modelpickles'], alg, 'model')\n",
    "\n",
    "    \n",
    "    feat_imp_ser = pd.Series(alg.booster().get_fscore()).head(10).sort_values(ascending=False)\n",
    "    feat_dict = feat_imp_ser.to_dict()\n",
    "    # run_stats.update({'Feature Importance Score': feat_dict})\n",
    "     \n",
    "    write_dict(run_stats, context['summary'], 'Results')\n",
    "    pickled = pickler(context['pickle'], run_stats, 'model results')\n",
    "    \n",
    "\n",
    "    plotCV(cvresult, optimal_boosters, context, acc_score_train, acc_score_valid, acc_score_test)\n",
    "    \n",
    "    \n",
    "    ##########Book keeping - update optimal parameters in dictionary with new boosters\n",
    "    \n",
    "    pickled = pickler(context['pickle'])\n",
    "    parameters = pickled['optimal parameters']\n",
    "\n",
    "    #native xgboost requires num_class, scikit_learn doesnt like it\n",
    "    del parameters['num_class']\n",
    "\n",
    "    #update with results\n",
    "    parameters.update({'n_estimators': optimal_boosters})\n",
    "\n",
    "    updated_pickle = pickler(context['pickle'], parameters, 'optimal parameters')\n",
    "    updated_pickle = pickler(context['pickle'], run_stats, 'run results')\n",
    "    write_dict(parameters, context['summary'],' Final Parameters')\n",
    "    \n",
    "    return updated_pickle\n",
    "    ########## End Book Keeping\n",
    " \n",
    "\n",
    "\n",
    "def plotCV(cvresult, optimal_boosters, context, accuracy_train = 0, accuracy_valid = 0, accuracy_test = 0,  title ='accuracy score by #estimators', ylim=(0.0,1)):\n",
    "    # ylim=(0.8,1.01)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (20,10)\n",
    "    plt.style.use('seaborn-colorblind')\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    watermark = mpimg.imread('../images/current_logo_gray.png')\n",
    "    \n",
    "    cvresult_df = pd.DataFrame(cvresult)\n",
    "    x_values = list(range(cvresult_df.shape[0]))\n",
    "    test_error = cvresult_df.iloc[:,0].tolist()\n",
    "    test_std = cvresult_df.iloc[:,1].tolist()\n",
    "    \n",
    "    train_error = cvresult_df.iloc[:,2].tolist()\n",
    "    train_std = cvresult_df.iloc[:,3].tolist()\n",
    "    \n",
    "    x_values_int= [None]*len(x_values)\n",
    "    test_error_float= [None]*len(x_values)\n",
    "    test_std_float= [None]*len(x_values)\n",
    "    train_error_float= [None]*len(x_values)\n",
    "    train_std_float= [None]*len(x_values)\n",
    "    \n",
    "    for i in range(len(x_values)):\n",
    "        x_values_int[i] = int(x_values[i])\n",
    "        test_error_float[i] = 1 - float(test_error[i])\n",
    "        test_std_float[i] = float(test_std[i])\n",
    "        train_error_float[i] = 1 - float(train_error[i])\n",
    "        train_std_float[i] = float(train_std[i])\n",
    "        \n",
    "      \n",
    "    fig = plt.figure()\n",
    "    plt.xlabel('number of boosters')\n",
    "    plt.ylabel('accuracy')\n",
    "    #plt.ylim(0.7,1,1)\n",
    "\n",
    "    plt.plot(x_values_int,\n",
    "         train_error_float,\n",
    "         label='Training Score',\n",
    "         color = 'r')\n",
    "\n",
    "    plt.plot(x_values_int,\n",
    "         test_error_float,\n",
    "         label='CV Score',\n",
    "         color = 'g')\n",
    "\n",
    "\n",
    "    plt.fill_between(x_values_int,\n",
    "                np.array(train_error_float) - np.array(train_std_float),\n",
    "                np.array(train_error_float) + np.array(train_std_float),\n",
    "                alpha =0.2, color ='r')\n",
    "\n",
    "    plt.fill_between(x_values_int,\n",
    "                np.array(test_error_float) - np.array(test_std_float),\n",
    "                np.array(test_error_float) + np.array(test_std_float),\n",
    "                alpha =0.2, color ='g')\n",
    "\n",
    "\n",
    "    plt.axhline(y = 1, color='k', ls ='dashed')\n",
    "    plt.axvline(x = optimal_boosters, ls ='dashed', label ='#estimators ' + str(optimal_boosters))\n",
    "\n",
    "    \n",
    "    plt.plot(optimal_boosters, float(accuracy_train), 'b^', label = 'Train Accuracy: ' + str(accuracy_train))\n",
    "    plt.plot(optimal_boosters, float(accuracy_valid), 'm^', label = 'Valid Accuracy: ' + str(accuracy_valid))\n",
    "    plt.plot(optimal_boosters, float(accuracy_test), 'g^', label = 'Test Accuracy: '+ str(accuracy_test))\n",
    "\n",
    "    \n",
    "    plt.legend(loc = 'best')\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.title(title)\n",
    "    \n",
    "    x_axis_range = plt.xlim()\n",
    "    y_axis_range = plt.ylim()\n",
    "\n",
    "    \n",
    "    imgplot = plt.imshow(watermark, aspect = 'auto', extent=(x_axis_range[0], x_axis_range[1],  y_axis_range[0],  y_axis_range[1]), zorder= - 1, alpha =0.1)\n",
    "\n",
    "    now = time.strftime(\"%H%M%S\",time.gmtime())\n",
    "    save_file = context['plot path'] + now + '.png'\n",
    "    plt.text(x_axis_range[0], y_axis_range[0], save_file, color='gray', fontsize=8)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(save_file, bbox_inches='tight')\n",
    "    pickled = pickler(context['pickle'], save_file, 'accuracy plot')\n",
    "\n",
    "\n",
    "def extend_single_param(result, delta_step, allowed_range, seen):\n",
    "    \n",
    "    new_list ={'left': round(result - delta_step, 2), 'right': round(result + delta_step, 2)}\n",
    "    \n",
    "    \n",
    "    if new_list['left'] <= allowed_range[0] or new_list['left'] in seen:\n",
    "        del new_list['left']\n",
    "    \n",
    "    if new_list['right'] > allowed_range[1] or new_list['right'] in seen:\n",
    "        del new_list['right']\n",
    "    \n",
    "    return list(new_list.values())\n",
    "\n",
    "\n",
    "\n",
    "def extend_param_dict(current_best, steps, allowed_ranges, seen):\n",
    "    #first find the extended range for each parameter\n",
    "    # step and allowed range and dictionaries for values for each tunable parameters\n",
    "    parameters ={}\n",
    "    for k, v in current_best.items():\n",
    "        seen_list = seen[k]\n",
    "        step =steps[k]\n",
    "        allowed_range = allowed_ranges[k]\n",
    "        print('parameter', k)\n",
    "        print('result:',v,' step:', step,' allowed_range:', allowed_range,' seen:', seen_list)\n",
    "        new_range = extend_single_param( v, step, allowed_range, seen_list)\n",
    "        print(new_range)\n",
    "        parameters.update({k:new_range})\n",
    "    \n",
    "    #iterate through new parameters - if none, set to incoming current best value\n",
    "    \n",
    "    for k, v in parameters.items():\n",
    "        if not v: parameters[k] = [current_best[k]]\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def remove_duplicates(inlist):\n",
    "    outlist =[]\n",
    "    for i in inlist:\n",
    "        if i not in outlist:\n",
    "            outlist.append(float(i))\n",
    "    \n",
    "    return outlist\n",
    "    \n",
    "\n",
    "def tuner_cv(estimator, train_set, train_labels, val_set, val_labels, param_test, tuning_rounds, steps, allowed_ranges, context, scoring ='accuracy', cv = 3, val_tuned =True):\n",
    "    \n",
    "    \n",
    "    tuning_results_params ={}\n",
    "    tuning_results_accuracy ={}\n",
    "    tuning_validation_accuracy ={}\n",
    "    rounds_to_tune = tuning_rounds\n",
    "\n",
    "    current_tuning_round = 0\n",
    "    \n",
    "    pickled = pickler(context['pickle'])\n",
    "    parameters = pickled['optimal parameters']\n",
    "#     estimator = XGBClassifier(**parameters)\n",
    "    estimator = estimator\n",
    "\n",
    "    tuned = False\n",
    "    param_test = param_test\n",
    "    seen = param_test\n",
    "\n",
    "\n",
    "    while not tuned:\n",
    "    \n",
    "        loop_result =()\n",
    "        \n",
    "        #update seen with parameters already tested\n",
    "        seen = { k:  seen[k] + param_test[k]  for k in seen }\n",
    "        seen = { k:  remove_duplicates(seen[k]) for k in seen }\n",
    "        \n",
    "        # Remove the duplicates\n",
    "        #seen = list(set(seen))\n",
    "    \n",
    "        gsearch = GridSearchCV(estimator = estimator, \n",
    "                        param_grid = param_test, \n",
    "                        scoring= scoring,\n",
    "                        n_jobs= -1,\n",
    "                        cv= cv)\n",
    "\n",
    "        loop_result = gsearch.fit(train_set, train_labels)\n",
    "        \n",
    "        # plot cv results\n",
    "        tuner_plot = plot_grid_search(loop_result, param_test, context)\n",
    "        \n",
    "        # score on the validation dataset\n",
    "        loop_result_val = loop_result.score(val_set, val_labels)\n",
    "\n",
    "        tuning_results_params.update({'iter'+str(current_tuning_round): loop_result.best_params_ })\n",
    "        tuning_results_accuracy.update({'iter'+str(current_tuning_round): loop_result.best_score_ })\n",
    "        tuning_validation_accuracy.update({'iter'+str(current_tuning_round): loop_result_val })\n",
    "    \n",
    "        print('Current Iteration ', loop_result.best_params_ , ' CV Accuracy ', loop_result.best_score_, ' Validation Accuracy ', loop_result_val)\n",
    "    \n",
    "    \n",
    "        current_tuning_round = current_tuning_round + 1\n",
    "    \n",
    "        param_test = extend_param_dict(loop_result.best_params_, steps, allowed_ranges, seen)\n",
    "        print(\"Extended List :\", param_test)\n",
    "        print('-------------------------------')\n",
    "    \n",
    "        #convert result dict values into list for comparison\n",
    "        best_params_list ={k: [loop_result.best_params_ [k]] for k in loop_result.best_params_ }\n",
    "        if param_test == best_params_list : tuned = True\n",
    "        if current_tuning_round == rounds_to_tune:  tuned = True\n",
    "    \n",
    "\n",
    "    \n",
    "    ##END WHILE TUNED  \n",
    "    write_dict(seen, context['summary'],'Tested Values')\n",
    "\n",
    "    #prepare dict for writing to file\n",
    "    tuner_results_summary ={key: str(tuning_results_params[key]) + '  CV Accuracy: ' + str(tuning_results_accuracy[key]) + '  Validation Accuracy: ' + str(tuning_validation_accuracy[key]) for key in tuning_results_params.keys() }\n",
    "\n",
    "    #compute the highest  CV accuracy \n",
    "    max_accuracy_key =max(tuning_results_accuracy, key=lambda key: tuning_results_accuracy[key])  \n",
    "    \n",
    "    #compute the highest Validation accuracy \n",
    "    if val_tuned: max_accuracy_key =max(tuning_validation_accuracy, key=lambda key: tuning_validation_accuracy[key])  \n",
    "\n",
    "    \n",
    "    # use CV accuracy for tuning\n",
    "    #tuning_results_params[max_accuracy_key]\n",
    "    \n",
    "    # use Validation accuracy for traiing\n",
    "    tuning_results_params[max_accuracy_key]\n",
    "\n",
    "    #pprint.pprint(tuner_results_summary)\n",
    "    write_dict(tuner_results_summary, context['summary'], 'Tuning Iterations')\n",
    "    write_dict({'Chosen:': str(tuning_results_params[max_accuracy_key]) + ' CV Accuracy: ' + str(tuning_results_accuracy[max_accuracy_key]) + ' Validation Accuracy: ' + str(tuning_validation_accuracy[max_accuracy_key])}, context['summary'])\n",
    "    \n",
    "\n",
    "    # Get the optimal parameters from the run\n",
    "    \n",
    "    # use Validation accuracy\n",
    "    params_to_update = tuning_results_params[max_accuracy_key]\n",
    "\n",
    "    # Update the parameters list with the new updated values for the params tested\n",
    "    parameters.update({k: params_to_update[k] for k in params_to_update.keys()})\n",
    "\n",
    "    # Update the pickle\n",
    "    updated_pickle = pickler(context['pickle'], parameters, 'optimal parameters')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_grid_search(tuner_results, param_grid, context):\n",
    "    \n",
    "    plt.style.use('seaborn-colorblind')\n",
    "    plt.rcParams['figure.figsize'] = (20,10)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    watermark = mpimg.imread('../images/current_logo_gray.png')\n",
    "    #titlefont = {'fontname':'COUR'}\n",
    "    \n",
    "    \n",
    "    #plots only the first two parameters\n",
    "    #check to ensure only two parameters are supplied\n",
    "    # catch 0 or > 2 parameters\n",
    "    \n",
    "    cv_results = tuner_results.cv_results_\n",
    "\n",
    "    \n",
    "\n",
    "    param_values =[]\n",
    "    param_names =[]\n",
    "    best_x = 0.0\n",
    "    best_y = 0.0\n",
    "    \n",
    "    # if grid search on just one parameter\n",
    "    if len(param_grid) == 1:\n",
    "        \n",
    "        scores_mean = np.array(cv_results['mean_test_score'])\n",
    "        scores_sd = np.array(cv_results['std_test_score'])\n",
    "        \n",
    "        #get the value of a single item dict\n",
    "        param_values = next(iter(param_grid.values()))\n",
    "        param_name = next(iter(param_grid.keys()))\n",
    "        \n",
    "        #_, ax = plt.subplots(1,1)\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        \n",
    "        plt.plot(param_values, scores_mean, '-o', label= param_name)\n",
    "        \n",
    "        plt.fill_between(param_values,\n",
    "                scores_mean + scores_sd,\n",
    "                scores_mean - scores_sd,\n",
    "                alpha =0.2)\n",
    "        \n",
    "        \n",
    "        best_x = float(next(iter(tuner_results.best_params_.values())))\n",
    "        best_y = float(tuner_results.best_score_)\n",
    "        \n",
    "        #ax.plot(best_x, best_y, 'g^', markersize=10,  label = 'Chosen Value ' + str(best_x) + ' Acc: ' + str(best_y))\n",
    "        \n",
    "        plt.title('tuned to ' + str(param_name))\n",
    "        plt.xlabel(str(param_name))\n",
    "        \n",
    "\n",
    "    \n",
    "    # if grid search on 2 parameters\n",
    "    if len(param_grid) == 2:\n",
    "        \n",
    "        for k, v in param_grid.items():\n",
    "            param_values.append(v)\n",
    "            param_names.append(k)\n",
    "        \n",
    "        \n",
    "        best_x = tuner_results.best_params_[param_names[0]]\n",
    "        best_y = float(tuner_results.best_score_)\n",
    "            \n",
    "    \n",
    "\n",
    "        # Get Test Scores Mean and std for each grid search\n",
    "        scores_mean = cv_results['mean_test_score']\n",
    "        scores_mean = np.array(scores_mean).reshape(len(param_values[0]),len(param_values[1]))\n",
    "\n",
    "        scores_sd = cv_results['std_test_score']\n",
    "        scores_sd = np.array(scores_sd).reshape(len(param_values[0]),len(param_values[1]))\n",
    "\n",
    "        # Plot Grid search scores\n",
    "        # _, ax = plt.subplots(1,1)\n",
    "        fig = plt.figure()\n",
    "\n",
    "        # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "        for idx, val in enumerate(param_values[1]):\n",
    "        \n",
    "            plt.plot(param_values[0], scores_mean[:, idx], '-o', label= param_names[1] + ': ' + str(val))\n",
    "            sd = scores_sd[:, idx]\n",
    "        \n",
    "            plt.fill_between(param_values[0],\n",
    "                scores_mean[:, idx] + sd,\n",
    "                scores_mean[:, idx] - sd,\n",
    "                alpha =0.2)\n",
    "            plt.title('tuning results for ' + str(param_names[0]) + ' & ' + str(param_names[1]))\n",
    "            plt.xlabel(param_names[0])\n",
    "            \n",
    "    \n",
    "    plt.plot(best_x, best_y, 'g^', markersize=10,  label = 'tuned to ' + str(tuner_results.best_params_) + '.  acc: ' + str(best_y))\n",
    "    plt.ylabel('accuracy')\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_axis_range = plt.xlim()\n",
    "    y_axis_range = plt.ylim()\n",
    "\n",
    "    \n",
    "    imgplot = plt.imshow(watermark, aspect = 'auto', extent=(x_axis_range[0], x_axis_range[1],  y_axis_range[0],  y_axis_range[1]), zorder= - 1, alpha =0.1)\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "#     plt.legend(frameon=True)\n",
    "#     leg = plt.legend()\n",
    "#     leg.draw_frame(True)\n",
    "#     leg.get_frame().set_edgecolor('b')\n",
    "    \n",
    "  \n",
    "    \n",
    "    now = time.strftime(\"%H%M%S\",time.gmtime())\n",
    "    save_file = context['plot path'] + now + '.png'\n",
    "    \n",
    "    plt.text(x_axis_range[0], y_axis_range[0], save_file, color='gray', fontsize=8)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(save_file, bbox_inches='tight')\n",
    "    \n",
    "    return save_file\n",
    "\n",
    "\n",
    "def show_random_samples(image_size, dataset, labels, description, context, rows = 1, cols=10):\n",
    "    \n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    #print(unique,counts)\n",
    "    font = {'family': 'monospace',\n",
    "        'color':  '#351c4d',\n",
    "        'weight': 'normal',\n",
    "        'size': 20,\n",
    "        }\n",
    "    \n",
    "    label_list = list(string.ascii_uppercase)\n",
    "    plt.rcParams['figure.figsize'] = (20,14)\n",
    "    plt.style.use('seaborn-colorblind')\n",
    "    #sns.set_style(\"whitegrid\")\n",
    "    watermark = mpimg.imread('../images/current_logo_gray.png')\n",
    "    footer_height =2\n",
    "    footer_width = 4\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    counter = 1\n",
    "    \n",
    "    for row in range(rows):\n",
    "  \n",
    "            for col in range(cols):\n",
    "                pick =   np.where(labels == col)[0] \n",
    "                random_pick = np.random.randint(len(pick))\n",
    "                sample_idx = pick[random_pick]\n",
    "                #print(sample_idx)\n",
    "                \n",
    "                #sample_idx = np.random.randint(len(dataset)) \n",
    "                sample_label = labels[sample_idx]  \n",
    "        \n",
    "                    \n",
    "                sample_image = dataset[sample_idx, :] \n",
    "                a=fig.add_subplot(rows + footer_height, cols, counter)\n",
    "                sample_image = sample_image.reshape(image_size, image_size)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(sample_image)\n",
    "                a.set_title(label_list[sample_label], fontsize=12, weight = 'bold',color = 'r')\n",
    "                counter+=1\n",
    "                    \n",
    "                \n",
    "    \n",
    "    \n",
    "   \n",
    "    for col in range(cols):\n",
    "                pick =   np.where(labels == col)[0] \n",
    "                random_pick = np.random.randint(len(pick))\n",
    "                sample_idx = pick[random_pick]\n",
    "                sample_label = labels[sample_idx]      \n",
    "                sample_image = dataset[sample_idx, :] \n",
    "                b=fig.add_subplot(rows + footer_height, cols, counter)\n",
    "                sample_image = sample_image.reshape(image_size, image_size)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(sample_image,cmap='Greys_r')\n",
    "                plt.tight_layout()\n",
    "                b.set_title(counts[sample_label], fontsize=15, weight = 'bold',color = '#351c4d')\n",
    "                counter+=1\n",
    "    \n",
    "    logo_footer= fig.add_subplot(rows + footer_height,footer_width,(rows+ footer_height)* footer_width)\n",
    "    x_axis_range = plt.xlim()\n",
    "    y_axis_range = plt.ylim()\n",
    "\n",
    "    #plt.axis('off')\n",
    "    #sns.set_style(\"whitegrid\")\n",
    "    plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "    \n",
    "    plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left='off',      # ticks along the bottom edge are off\n",
    "    right='off',         # ticks along the top edge are off\n",
    "    labelleft='off') # labels along the bottom edge are off\n",
    "    \n",
    "    imgplot = plt.imshow(watermark, aspect = 'auto', extent=(x_axis_range[0], x_axis_range[1],  y_axis_range[0],  y_axis_range[1]), zorder= - 1, alpha =0.3)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    title_footer= fig.add_subplot(rows + footer_height,2,(rows+ footer_height)* 2-1)\n",
    "    plt.axis('off')\n",
    "    x_axis_range = plt.xlim()\n",
    "    y_axis_range = plt.ylim()\n",
    "    plt.text(0, 0, description + str(dataset.shape), va='center', fontdict=font, fontsize=40)\n",
    "    \n",
    "    now = time.strftime(\"%H%M%S\",time.gmtime())\n",
    "    save_file = context['plot path'] + now + '.png'\n",
    "    \n",
    "    plt.text(x_axis_range[0], y_axis_range[0], save_file, color='gray', fontsize=8)\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(save_file, bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
